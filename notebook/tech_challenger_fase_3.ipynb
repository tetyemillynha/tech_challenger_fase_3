{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8f72b9f0839f4e2081848f2c99de7763": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f547249e30534f66b0b1eda510de1ede",
              "IPY_MODEL_b1c13fc600174ac5a3a859ed27e483c2",
              "IPY_MODEL_09e0e2aa7ec04fb4b1c9d9df97d1da84"
            ],
            "layout": "IPY_MODEL_a52c523507c248948605b86c085b41fa"
          }
        },
        "f547249e30534f66b0b1eda510de1ede": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_285e819c6ab44dbcb384daabd56bcae3",
            "placeholder": "​",
            "style": "IPY_MODEL_40c6911473d947dc82d3c1161f35396e",
            "value": "Map: 100%"
          }
        },
        "b1c13fc600174ac5a3a859ed27e483c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48ec14649d4e4b3fa530821f45bf7803",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62c4487738444b1a888b365cb9b513d3",
            "value": 10000
          }
        },
        "09e0e2aa7ec04fb4b1c9d9df97d1da84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5589f39eb41c41d3a1c6ddb50753efa6",
            "placeholder": "​",
            "style": "IPY_MODEL_16ad835bfec945ea8a7d1851c0caa640",
            "value": " 10000/10000 [00:03&lt;00:00, 3614.17 examples/s]"
          }
        },
        "a52c523507c248948605b86c085b41fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "285e819c6ab44dbcb384daabd56bcae3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40c6911473d947dc82d3c1161f35396e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48ec14649d4e4b3fa530821f45bf7803": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62c4487738444b1a888b365cb9b513d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5589f39eb41c41d3a1c6ddb50753efa6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16ad835bfec945ea8a7d1851c0caa640": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "841c8ec98d1744e086ba915c39c2a217": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f260b62e286642fea79a52af572ad86b",
              "IPY_MODEL_7e10856680724552be9b368b371a91f6",
              "IPY_MODEL_f78c9898063944fd92204e269a2ca7c0"
            ],
            "layout": "IPY_MODEL_8c41731620de4abdabd94e1618e254c6"
          }
        },
        "f260b62e286642fea79a52af572ad86b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d417afadc5a1450e9e3099e74458ccf8",
            "placeholder": "​",
            "style": "IPY_MODEL_4b273e333316400892b58486597e7698",
            "value": "Map: 100%"
          }
        },
        "7e10856680724552be9b368b371a91f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84bbe6beabe94d25bb3cae50f338d16c",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b3bf5eed98164ff1b1708042055ba168",
            "value": 10000
          }
        },
        "f78c9898063944fd92204e269a2ca7c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d85d5f057a2842c59071309088723365",
            "placeholder": "​",
            "style": "IPY_MODEL_53594628611d4678bd38fe184cff68c6",
            "value": " 10000/10000 [00:08&lt;00:00, 1109.84 examples/s]"
          }
        },
        "8c41731620de4abdabd94e1618e254c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d417afadc5a1450e9e3099e74458ccf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b273e333316400892b58486597e7698": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84bbe6beabe94d25bb3cae50f338d16c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3bf5eed98164ff1b1708042055ba168": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d85d5f057a2842c59071309088723365": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53594628611d4678bd38fe184cff68c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Instalação simples para Google Colab\n",
        "!pip install --upgrade pip\n",
        "\n",
        "# Instalar todas as dependências de uma vez\n",
        "!pip install \"transformers>=4.46,<4.47\" \"accelerate>=0.34,<0.35\" \"peft>=0.11.1\" \"bitsandbytes>=0.43.1\" \"datasets>=2.20.0\" \"evaluate>=0.4.2\" \"rouge-score>=0.1.2\" \"bert-score>=0.3.13\" \"sentencepiece>=0.2.0\" \"einops>=0.8.0\" \"torch>=2.3.0\"\n",
        "\n",
        "# Verificar instalação\n",
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "import transformers\n",
        "print(f\"Transformers version: {transformers.__version__}\")\n",
        "\n",
        "print(\"Instalação concluída!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4aUu4VCZpYW",
        "outputId": "3dba5d75-7e93-43f4-bb31-bbe15f081b9d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.2\n",
            "Collecting transformers<4.47,>=4.46\n",
            "  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
            "Collecting accelerate<0.35,>=0.34\n",
            "  Downloading accelerate-0.34.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: peft>=0.11.1 in /usr/local/lib/python3.12/dist-packages (0.17.1)\n",
            "Collecting bitsandbytes>=0.43.1\n",
            "  Downloading bitsandbytes-0.48.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: datasets>=2.20.0 in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Collecting evaluate>=0.4.2\n",
            "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting rouge-score>=0.1.2\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bert-score>=0.3.13\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: einops>=0.8.0 in /usr/local/lib/python3.12/dist-packages (0.8.1)\n",
            "Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers<4.47,>=4.46) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.12/dist-packages (from transformers<4.47,>=4.46) (0.35.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers<4.47,>=4.46) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers<4.47,>=4.46) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers<4.47,>=4.46) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<4.47,>=4.46) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers<4.47,>=4.46) (2.32.4)\n",
            "Collecting tokenizers<0.21,>=0.20 (from transformers<4.47,>=4.46)\n",
            "  Downloading tokenizers-0.20.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers<4.47,>=4.46) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers<4.47,>=4.46) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate<0.35,>=0.34) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers<4.47,>=4.46) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers<4.47,>=4.46) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers<4.47,>=4.46) (1.1.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3.0) (3.4.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.20.0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.20.0) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets>=2.20.0) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=2.20.0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.20.0) (0.70.16)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.20.0) (3.12.15)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge-score>=0.1.2) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge-score>=0.1.2) (3.9.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge-score>=0.1.2) (1.17.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from bert-score>=0.3.13) (3.10.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.20.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.20.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.20.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.20.0) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.20.0) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.20.0) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.20.0) (1.20.1)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.20.0) (3.10)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=2.20.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=2.20.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=2.20.0) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<4.47,>=4.46) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<4.47,>=4.46) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<4.47,>=4.46) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.3.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.3.0) (3.0.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score>=0.3.13) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score>=0.3.13) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score>=0.3.13) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score>=0.3.13) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score>=0.3.13) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->bert-score>=0.3.13) (3.2.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge-score>=0.1.2) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge-score>=0.1.2) (1.5.2)\n",
            "Downloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m127.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-0.34.2-py3-none-any.whl (324 kB)\n",
            "Downloading tokenizers-0.20.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.48.1-py3-none-manylinux_2_24_x86_64.whl (60.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
            "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "Building wheels for collected packages: rouge-score\n",
            "\u001b[33m  DEPRECATION: Building 'rouge-score' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'rouge-score'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=533e6d5a0ab8e3ead48c7b5d4b8d3185eecbb1f63e5031f1890b0812e33d266b\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score, tokenizers, transformers, bitsandbytes, accelerate, evaluate, bert-score\n",
            "\u001b[2K  Attempting uninstall: tokenizers\n",
            "\u001b[2K    Found existing installation: tokenizers 0.22.1\n",
            "\u001b[2K    Uninstalling tokenizers-0.22.1:\n",
            "\u001b[2K      Successfully uninstalled tokenizers-0.22.1\n",
            "\u001b[2K  Attempting uninstall: transformers\n",
            "\u001b[2K    Found existing installation: transformers 4.56.2\n",
            "\u001b[2K    Uninstalling transformers-4.56.2:\n",
            "\u001b[2K      Successfully uninstalled transformers-4.56.2\n",
            "\u001b[2K  Attempting uninstall: accelerate\n",
            "\u001b[2K    Found existing installation: accelerate 1.10.1\n",
            "\u001b[2K    Uninstalling accelerate-1.10.1:\n",
            "\u001b[2K      Successfully uninstalled accelerate-1.10.1\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7/7\u001b[0m [bert-score]\n",
            "\u001b[1A\u001b[2KSuccessfully installed accelerate-0.34.2 bert-score-0.3.13 bitsandbytes-0.48.1 evaluate-0.4.6 rouge-score-0.1.2 tokenizers-0.20.3 transformers-4.46.3\n",
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA available: True\n",
            "GPU: Tesla T4\n",
            "Transformers version: 4.46.3\n",
            "✅ Instalação concluída!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Preparação do dataset ===\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import os, json, random\n",
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "DS_DIR = \"/content/drive/MyDrive/amazon_ft/cache/prepared_descfmt\"\n",
        "\n",
        "# Localiza o arquivo dataset\n",
        "if os.path.exists(DS_DIR):\n",
        "    print(\"Dataset já existe no Drive:\", DS_DIR)\n",
        "else:\n",
        "    print(\"Criando dataset com formato 'Description: ...' em:\", DS_DIR)\n",
        "    candidates = [\n",
        "        \"/content/data/trn.json\",\n",
        "        \"/content/drive/MyDrive/projeto_fase_3/trn.json\",\n",
        "        \"/content/drive/MyDrive/trn.json\",\n",
        "    ]\n",
        "    json_path = next((p for p in candidates if os.path.exists(p)), None)\n",
        "    if json_path is None:\n",
        "        raise FileNotFoundError(\n",
        "            \"Não encontrou o trn.json. Faça upload em /content/data/trn.json \"\n",
        "            \"ou copie para /content/drive/MyDrive/projeto_fase_3/trn.json\"\n",
        "        )\n",
        "\n",
        "    # Em ingles porque obteve melhores resultados\n",
        "    QUESTION = \"What is the complete product description? Answer strictly in the format: 'Description: ...' and nothing else.\"\n",
        "    N_TRAIN, N_VAL, N_TEST = 10000, 1000, 1000\n",
        "\n",
        "    def build_example(title, content):\n",
        "        user = (\n",
        "            \"Based on the product title below, answer the question.\\n\"\n",
        "            f\"Question: {QUESTION}\\n\"\n",
        "            f\"Title: {title.strip()}\"\n",
        "        )\n",
        "        target = \"Description: \" + content.strip()\n",
        "        return {\"input_text\": user, \"target_text\": target}\n",
        "\n",
        "    # Cria pares de entrada e alvo (input e target)\n",
        "    pairs = []\n",
        "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            try:\n",
        "                ex = json.loads(line)\n",
        "            except Exception:\n",
        "                continue\n",
        "            title = (ex.get(\"title\") or \"\").strip()\n",
        "            content = (ex.get(\"content\") or \"\").strip()\n",
        "            if len(title) < 3 or len(content) < 20:\n",
        "                continue\n",
        "            pairs.append(build_example(title, content))\n",
        "\n",
        "    random.seed(42)\n",
        "    random.shuffle(pairs)\n",
        "    need = N_TRAIN + N_VAL + N_TEST\n",
        "    pairs = pairs[:need]\n",
        "\n",
        "    # Separa em train/val/test\n",
        "    train_pairs = pairs[:N_TRAIN]\n",
        "    val_pairs   = pairs[N_TRAIN:N_TRAIN+N_VAL]\n",
        "    test_pairs  = pairs[N_TRAIN+N_VAL:N_TRAIN+N_VAL+N_TEST]\n",
        "\n",
        "    # Salva no Drive\n",
        "    ds = DatasetDict({\n",
        "        \"train\": Dataset.from_list(train_pairs),\n",
        "        \"validation\": Dataset.from_list(val_pairs),\n",
        "        \"test\": Dataset.from_list(test_pairs),\n",
        "    })\n",
        "    os.makedirs(DS_DIR, exist_ok=True)\n",
        "    ds.save_to_disk(DS_DIR)\n",
        "\n",
        "    print(\"Dataset salvo no Drive:\", DS_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-MYcg0qZ-JU",
        "outputId": "032c8f5b-5526-46fc-bf89-afc6f68556f0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Dataset já existe no Drive: /content/drive/MyDrive/amazon_ft/cache/prepared_descfmt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Fine-tuning QLoRA no TinyLlama ===\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import os, types, torch\n",
        "from datasets import load_from_disk\n",
        "from transformers import (AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig,\n",
        "                          DataCollatorForLanguageModeling, TrainingArguments, Trainer)\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "\n",
        "# ===== CONFIG BÁSICA =====\n",
        "MODEL_NAME    = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "PREP_DIR      = \"/content/drive/MyDrive/amazon_ft/cache/prepared_descfmt\"\n",
        "OUT_DIR       = \"/content/drive/MyDrive/amazon_ft/outputs/tinyllama11b_descfmt_lora\"\n",
        "ADAPTER_DIR   = f\"{OUT_DIR}/adapter\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "ds = load_from_disk(PREP_DIR)\n",
        "\n",
        "# Carrego o tiny já compactado em 4bit\n",
        "bnb = BitsAndBytesConfig(\n",
        "    load_in_4bit=True, bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True, bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "tok = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True, trust_remote_code=True)\n",
        "if tok.pad_token is None: tok.pad_token = tok.eos_token\n",
        "\n",
        "base = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME, quantization_config=bnb, device_map=\"auto\", trust_remote_code=True\n",
        ")\n",
        "base = prepare_model_for_kbit_training(base)\n",
        "\n",
        "# LoRA abrangente (garante que o modelo \"escute\" o adapter)\n",
        "lora_cfg = LoraConfig(\n",
        "    r=32, lora_alpha=64, lora_dropout=0.05, task_type=\"CAUSAL_LM\",\n",
        "    target_modules=\"all-linear\", modules_to_save=[\"lm_head\",\"embed_tokens\"]\n",
        ")\n",
        "model = get_peft_model(base, lora_cfg)\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "# Formatação e tokenização\n",
        "def format_chat(example):\n",
        "    messages = [\n",
        "        {\"role\":\"user\", \"content\": example[\"input_text\"]},\n",
        "        {\"role\":\"assistant\", \"content\": example[\"target_text\"]},\n",
        "    ]\n",
        "    text = tok.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)\n",
        "    return {\"text\": text}\n",
        "\n",
        "# ===== PREPARAÇÃO DO DATASET =====\n",
        "train_txt = ds[\"train\"].map(format_chat, remove_columns=ds[\"train\"].column_names)\n",
        "def tok_fn(e): return tok(e[\"text\"], truncation=True, max_length=512)\n",
        "train_tok = train_txt.map(tok_fn, batched=True, remove_columns=[\"text\"])\n",
        "collator = DataCollatorForLanguageModeling(tok, mlm=False)\n",
        "\n",
        "# ===== ARGS DE TREINO =====\n",
        "args = TrainingArguments(\n",
        "    output_dir=OUT_DIR,\n",
        "    max_steps=5000,\n",
        "    num_train_epochs=1,\n",
        "    learning_rate=1e-4,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    warmup_ratio=0.03,\n",
        "    gradient_accumulation_steps=8,\n",
        "    per_device_train_batch_size=2,\n",
        "    logging_steps=20,\n",
        "    eval_strategy=\"no\",\n",
        "    save_steps=5000,\n",
        "    save_total_limit=1,\n",
        "    bf16=False, fp16=True,\n",
        "    report_to=\"none\",\n",
        "    optim=\"adamw_torch\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(model=model, args=args, train_dataset=train_tok, data_collator=collator)\n",
        "\n",
        "# Patch accelerate (evita erro \"optimizer.train()\")\n",
        "try:\n",
        "    from accelerate.optimizer import AcceleratedOptimizer\n",
        "    _noop=lambda self,*a,**k: None\n",
        "    AcceleratedOptimizer.train = types.MethodType(_noop, AcceleratedOptimizer)\n",
        "    AcceleratedOptimizer.eval  = types.MethodType(_noop,  AcceleratedOptimizer)\n",
        "except: pass\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# ===== SALVANDO O ADAPTER =====\n",
        "os.makedirs(ADAPTER_DIR, exist_ok=True)\n",
        "model.save_pretrained(ADAPTER_DIR)\n",
        "print(\"Adapter salvo em:\", ADAPTER_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8f72b9f0839f4e2081848f2c99de7763",
            "f547249e30534f66b0b1eda510de1ede",
            "b1c13fc600174ac5a3a859ed27e483c2",
            "09e0e2aa7ec04fb4b1c9d9df97d1da84",
            "a52c523507c248948605b86c085b41fa",
            "285e819c6ab44dbcb384daabd56bcae3",
            "40c6911473d947dc82d3c1161f35396e",
            "48ec14649d4e4b3fa530821f45bf7803",
            "62c4487738444b1a888b365cb9b513d3",
            "5589f39eb41c41d3a1c6ddb50753efa6",
            "16ad835bfec945ea8a7d1851c0caa640",
            "841c8ec98d1744e086ba915c39c2a217",
            "f260b62e286642fea79a52af572ad86b",
            "7e10856680724552be9b368b371a91f6",
            "f78c9898063944fd92204e269a2ca7c0",
            "8c41731620de4abdabd94e1618e254c6",
            "d417afadc5a1450e9e3099e74458ccf8",
            "4b273e333316400892b58486597e7698",
            "84bbe6beabe94d25bb3cae50f338d16c",
            "b3bf5eed98164ff1b1708042055ba168",
            "d85d5f057a2842c59071309088723365",
            "53594628611d4678bd38fe184cff68c6"
          ]
        },
        "id": "lfEkGGH7aQnv",
        "outputId": "3c25cd0c-41a8-470b-fac7-1d0784e9eaf1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "trainable params: 156,303,360 || all params: 1,256,351,744 || trainable%: 12.4411\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f72b9f0839f4e2081848f2c99de7763"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "841c8ec98d1744e086ba915c39c2a217"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
            "max_steps is given, it will override any value given in num_train_epochs\n",
            "/usr/local/lib/python3.12/dist-packages/torch/_dynamo/eval_frame.py:929: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1300' max='1300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1300/1300 1:41:13, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>2.245200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.781400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.798300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.780700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.773500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.792100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>1.763300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>1.731900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>1.731800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.736800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>1.762400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>1.743000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>1.757500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>1.738600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.759100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>1.711500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>1.778900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>1.775600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>1.759800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.747900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>1.711700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>1.670500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>1.767500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>1.758200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.703600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>1.710900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>1.720400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>1.773600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>1.745100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.731300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>1.765600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>1.515100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>1.440300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>1.409400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>1.424100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>1.403200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>1.404200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>1.403300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>1.441600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>1.405000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>1.423300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>1.422800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>1.383700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>1.405100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>1.417500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>1.412200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>1.407600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>1.378100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>1.401500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.401300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1020</td>\n",
              "      <td>1.386500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1040</td>\n",
              "      <td>1.424400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1060</td>\n",
              "      <td>1.388600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1080</td>\n",
              "      <td>1.417600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>1.451300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1120</td>\n",
              "      <td>1.402200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1140</td>\n",
              "      <td>1.394700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1160</td>\n",
              "      <td>1.409800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1180</td>\n",
              "      <td>1.386200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>1.403400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1220</td>\n",
              "      <td>1.413600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1240</td>\n",
              "      <td>1.370300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1260</td>\n",
              "      <td>1.338800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1280</td>\n",
              "      <td>1.321500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>1.294400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adapter salvo em: /content/drive/MyDrive/amazon_ft/outputs/tinyllama11b_descfmt_lora/adapter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Merge do LoRA em fp16 (modelo único para inferência) ===\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import os, torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import PeftModel\n",
        "\n",
        "# ===== CONFIG BÁSICA =====\n",
        "MODEL_NAME  = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "ADAPTER_DIR = \"/content/drive/MyDrive/amazon_ft/outputs/tinyllama11b_descfmt_lora/adapter\"\n",
        "SAVE_DIR    = \"/content/drive/MyDrive/amazon_ft/outputs/tinyllama11b_descfmt_merged_fp16\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# ===== PREPARAÇÃO DO TOKENIZADOR =====\n",
        "tok = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True, trust_remote_code=True)\n",
        "if tok.pad_token is None: tok.pad_token = tok.eos_token\n",
        "\n",
        "# Tenta GPU; se OOM, cai para CPU automaticamente\n",
        "def try_gpu_then_cpu():\n",
        "    try:\n",
        "        base = AutoModelForCausalLM.from_pretrained(\n",
        "            MODEL_NAME, device_map=None, torch_dtype=torch.float16, trust_remote_code=True\n",
        "        ).to(\"cuda\")\n",
        "        ft = PeftModel.from_pretrained(base, ADAPTER_DIR, is_trainable=False)\n",
        "        merged = ft.merge_and_unload()\n",
        "        merged.save_pretrained(SAVE_DIR); tok.save_pretrained(SAVE_DIR)\n",
        "        print(\"Merge em GPU concluído:\", SAVE_DIR)\n",
        "    except Exception as e:\n",
        "        print(\"Aviso: GPU falhou, tentando em CPU (pode demorar). Detalhe:\", e)\n",
        "        base = AutoModelForCausalLM.from_pretrained(\n",
        "            MODEL_NAME, device_map=None, torch_dtype=torch.float32, trust_remote_code=True\n",
        "        )  # CPU em fp32 para segurança\n",
        "        ft = PeftModel.from_pretrained(base, ADAPTER_DIR, is_trainable=False)\n",
        "        merged = ft.merge_and_unload()\n",
        "        merged.save_pretrained(SAVE_DIR); tok.save_pretrained(SAVE_DIR)\n",
        "        print(\"Merge em CPU concluído:\", SAVE_DIR)\n",
        "\n",
        "try_gpu_then_cpu()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUChpdF6zt6X",
        "outputId": "621986c8-aa91-4aaf-9243-573dcda226b7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Merge em GPU concluído: /content/drive/MyDrive/amazon_ft/outputs/tinyllama11b_descfmt_merged_fp16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Avaliação rápida: BASE (4-bit) vs MERGED (4-bit) ===\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import os, json, random, pandas as pd, torch, shutil\n",
        "from datasets import load_from_disk\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "# ===== CONFIG BÁSICA =====\n",
        "MODEL_NAME = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "MERGED_DIR = \"/content/drive/MyDrive/amazon_ft/outputs/tinyllama11b_descfmt_merged_fp16\"\n",
        "PREP_DIR   = \"/content/drive/MyDrive/amazon_ft/cache/prepared_descfmt\"\n",
        "OUT_CSV    = \"/content/drive/MyDrive/amazon_ft/outputs/side_by_side_tinyllama_descfmt_merged_quick.csv\"\n",
        "OUT_JSON   = \"/content/drive/MyDrive/amazon_ft/outputs/metrics_tinyllama_descfmt_merged_quick.json\"\n",
        "\n",
        "K        = 30\n",
        "MAX_NEW  = 150\n",
        "\n",
        "# Métricas\n",
        "try:\n",
        "    import evaluate\n",
        "except Exception:\n",
        "    import sys, subprocess\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", \"evaluate\", \"rouge-score\"])\n",
        "    import evaluate\n",
        "\n",
        "# Limpa cache da GPU\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# Carrega dataset\n",
        "ds = load_from_disk(PREP_DIR)\n",
        "tok = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True, trust_remote_code=True)\n",
        "if tok.pad_token is None: tok.pad_token = tok.eos_token\n",
        "\n",
        "# Configuração de 4-bit\n",
        "bnb_cfg = BitsAndBytesConfig(\n",
        "    load_in_4bit=True, bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True, bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "# Diretório de offload\n",
        "offload_dir = \"/content/offload_eval\"; shutil.rmtree(offload_dir, ignore_errors=True); os.makedirs(offload_dir, exist_ok=True)\n",
        "\n",
        "# Carrega modelos\n",
        "base = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME, device_map=\"auto\", trust_remote_code=True,\n",
        "    quantization_config=bnb_cfg, offload_buffers=True, offload_folder=offload_dir\n",
        ")\n",
        "merged = AutoModelForCausalLM.from_pretrained(\n",
        "    MERGED_DIR, device_map=\"auto\", trust_remote_code=True,\n",
        "    quantization_config=bnb_cfg, offload_buffers=True, offload_folder=offload_dir\n",
        ")\n",
        "\n",
        "# Função de geração de chat\n",
        "def chat_generate(model, user_text, max_new_tokens=MAX_NEW):\n",
        "    prompt = tok.apply_chat_template([{\"role\":\"user\",\"content\":user_text}],\n",
        "                                     tokenize=False, add_generation_prompt=True)\n",
        "    inputs = tok(prompt, return_tensors=\"pt\")  # fica no CPU; accelerate despacha\n",
        "    with torch.no_grad():\n",
        "        out = model.generate(**inputs, max_new_tokens=max_new_tokens, do_sample=False,\n",
        "                             pad_token_id=tok.eos_token_id, use_cache=True)\n",
        "    gen_ids = out[0][inputs[\"input_ids\"].shape[-1]:]\n",
        "    return tok.decode(gen_ids, skip_special_tokens=True).strip()\n",
        "\n",
        "# Amostra aleatória de índices\n",
        "random.seed(42)\n",
        "idxs = random.sample(range(len(ds[\"test\"])), k=min(K, len(ds[\"test\"])))\n",
        "\n",
        "rows, preds_base, preds_ft, refs = [], [], [], []\n",
        "for i in idxs:\n",
        "    ex  = ds[\"test\"][i]\n",
        "    inp = ex[\"input_text\"]; ref = ex[\"target_text\"]\n",
        "    yb = chat_generate(base,   inp)\n",
        "    ym = chat_generate(merged, inp)\n",
        "    rows.append({\n",
        "        \"id\": i,\n",
        "        \"input_preview\": inp[:140].replace(\"\\n\",\" \") + \"...\",\n",
        "        \"reference_preview\": ref[:200].replace(\"\\n\",\" \") + \"...\",\n",
        "        \"baseline\": yb,\n",
        "        \"fine_tuned_merged\": ym,\n",
        "    })\n",
        "    preds_base.append(yb); preds_ft.append(ym); refs.append(ref)\n",
        "\n",
        "# Salva CSV\n",
        "os.makedirs(os.path.dirname(OUT_CSV), exist_ok=True)\n",
        "pd.DataFrame(rows).to_csv(OUT_CSV, index=False)\n",
        "print(\"CSV salvo em:\", OUT_CSV)\n",
        "\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "r_base = rouge.compute(predictions=preds_base, references=refs)\n",
        "r_ft   = rouge.compute(predictions=preds_ft,   references=refs)\n",
        "\n",
        "metrics = {\"rouge_base\": {k: float(v) for k,v in r_base.items()},\n",
        "           \"rouge_ft\":   {k: float(v) for k,v in r_ft.items()}}\n",
        "with open(OUT_JSON, \"w\") as f:\n",
        "    json.dump(metrics, f, indent=2)\n",
        "print(\"Métricas (ROUGE) salvas em:\", OUT_JSON)\n",
        "print(\"Resumo:\", metrics)\n"
      ],
      "metadata": {
        "id": "m1UjU-yM1P7D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}